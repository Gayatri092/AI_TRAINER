{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e31e7b4-0382-4d45-826f-b232c4f9c286",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of fuzzy matched workouts: 973\n",
      "Combined shape after fuzzy merge: (1630286, 38)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# Import fuzzy matching library\n",
    "from rapidfuzz import process, fuzz\n",
    "\n",
    "# Step 2: Load datasets (adjust paths if needed)\n",
    "gym_members_df = pd.read_csv('gym_members_exercise_tracking.csv')\n",
    "workout_tracker_df = pd.read_csv('workout_fitness_tracker_data.csv')\n",
    "\n",
    "# Step 3: Clean text function for merge keys (improved with extra normalization)\n",
    "def clean_text(s):\n",
    "    if isinstance(s, str):\n",
    "        s = s.lower().strip()\n",
    "        s = s.replace('-', ' ').replace('_', ' ')\n",
    "        s = ''.join(c for c in s if c.isalnum() or c.isspace())\n",
    "        s = ' '.join(word for word in s.split() if word not in {'the', 'and', 'of', 'in'})  # remove common stopwords\n",
    "        return s\n",
    "    return ''\n",
    "\n",
    "# Step 4: Clean and create merge keys\n",
    "gym_members_df['workout_clean'] = gym_members_df['Workout_Type'].apply(clean_text)\n",
    "workout_tracker_df['workout_clean'] = workout_tracker_df['Workout Type'].apply(clean_text)\n",
    "\n",
    "# Step 5: Fuzzy matching - find best matches for each gym workout in tracker dataset\n",
    "\n",
    "# Make list of unique workouts in tracker dataset for matching\n",
    "tracker_workouts = workout_tracker_df['workout_clean'].unique().tolist()\n",
    "\n",
    "def get_best_match(name):\n",
    "    if not name:\n",
    "        return None\n",
    "    match, score, _ = process.extractOne(name, tracker_workouts, scorer=fuzz.token_sort_ratio)\n",
    "    return match if score >= 80 else None  # threshold can be adjusted\n",
    "\n",
    "# Apply fuzzy matching to gym_members workout_clean column\n",
    "gym_members_df['fuzzy_match'] = gym_members_df['workout_clean'].apply(get_best_match)\n",
    "\n",
    "# Filter gym_members to those successfully matched\n",
    "gym_members_filtered = gym_members_df[gym_members_df['fuzzy_match'].notna()].copy()\n",
    "print(f\"Number of fuzzy matched workouts: {len(gym_members_filtered)}\")\n",
    "\n",
    "# Step 6 (Optional): Merge on broader category if available\n",
    "# Uncomment & adjust if you want to try merge on a broader feature like 'Type' or 'Category'\n",
    "# Example:\n",
    "# if 'Type' in gym_members_df.columns and 'Type' in workout_tracker_df.columns:\n",
    "#     combined_df = pd.merge(gym_members_df, workout_tracker_df, left_on='Type', right_on='Type', how='inner')\n",
    "#     print(f\"Shape after merge on Type: {combined_df.shape}\")\n",
    "# else:\n",
    "#     # Use fuzzy match key for merging (Step 7 below)\n",
    "\n",
    "# Step 7: Merge on fuzzy matched workout names\n",
    "combined_df = pd.merge(\n",
    "    gym_members_filtered, workout_tracker_df,\n",
    "    left_on='fuzzy_match', right_on='workout_clean',\n",
    "    how='left', suffixes=('_gym', '_tracker')\n",
    ")\n",
    "print(f\"Combined shape after fuzzy merge: {combined_df.shape}\")\n",
    "\n",
    "# Step 8: Handle missing values - avoid inplace chained assignment\n",
    "for col in combined_df.select_dtypes(include=[np.number]).columns:\n",
    "    combined_df[col] = combined_df[col].fillna(combined_df[col].median())\n",
    "\n",
    "for col in combined_df.select_dtypes(include='object').columns:\n",
    "    combined_df[col] = combined_df[col].fillna('missing')\n",
    "\n",
    "# Step 9: Define feature columns as before (ensure names exist)\n",
    "feature_cols = [\n",
    "    'Age_gym', 'Gender_gym', 'Weight (kg)_gym', 'Height (m)', 'Calories_Burned_gym',\n",
    "    'Max_BPM', 'Avg_BPM', 'Resting_BPM', 'Session_Duration (hours)',\n",
    "    'Workout Duration (mins)', 'Calories Burned', 'Heart Rate (bpm)', 'Steps Taken',\n",
    "    'Distance (km)', 'Workout Intensity'\n",
    "]\n",
    "feature_cols = [col for col in feature_cols if col in combined_df.columns]\n",
    "\n",
    "# Identify categorical and numeric features\n",
    "cat_features = [col for col in feature_cols if combined_df[col].dtype == 'object']\n",
    "num_features = [col for col in feature_cols if col not in cat_features]\n",
    "\n",
    "# Label encode categorical features\n",
    "for col in cat_features:\n",
    "    le = LabelEncoder()\n",
    "    combined_df[col] = le.fit_transform(combined_df[col].astype(str))\n",
    "\n",
    "# Step 10: Prepare X, y for model\n",
    "X = combined_df[feature_cols].copy()  # avoid SettingWithCopyWarning\n",
    "\n",
    "if 'Experience_Level' in combined_df.columns:\n",
    "    y = combined_df['Experience_Level']\n",
    "elif 'Workout Intensity' in combined_df.columns:\n",
    "    y = combined_df['Workout Intensity']\n",
    "else:\n",
    "    raise ValueError(\"No suitable target column found\")\n",
    "\n",
    "# Step 11: Scale numeric features\n",
    "scaler = StandardScaler()\n",
    "X[num_features] = scaler.fit_transform(X[num_features])\n",
    "\n",
    "# Step 12: Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Step 13: Train Random Forest model\n",
    "model = RandomForestClassifier(n_estimators=200, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Step 14: Predict and evaluation\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8f056a15-6f73-4c10-8b8e-35a8e26025af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined df shape: (1630286, 36)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load datasets\n",
    "gym_members_df = pd.read_csv('gym_members_exercise_tracking.csv')\n",
    "workout_tracker_df = pd.read_csv('workout_fitness_tracker_data.csv')\n",
    "\n",
    "# Vectorized text cleaning function for workout type columns\n",
    "def fast_clean_text(series):\n",
    "    return (series.str.lower()\n",
    "                  .str.strip()\n",
    "                  .str.replace('[-_]', ' ', regex=True)          # replace hyphens and underscores with space\n",
    "                  .str.replace('[^a-z0-9 ]', '', regex=True)    # keep only alphanumeric and spaces\n",
    "                  .str.replace(r'\\s+', ' ', regex=True))        # collapse multiple spaces into one\n",
    "\n",
    "# Apply cleaning with vectorized pandas string methods (much faster than apply)\n",
    "gym_members_df['workout_clean'] = fast_clean_text(gym_members_df['Workout_Type'])\n",
    "workout_tracker_df['workout_clean'] = fast_clean_text(workout_tracker_df['Workout Type'])\n",
    "\n",
    "# Optional: convert to category dtype for memory efficiency and faster merge (optional but recommended)\n",
    "gym_members_df['workout_clean'] = gym_members_df['workout_clean'].astype('category')\n",
    "workout_tracker_df['workout_clean'] = workout_tracker_df['workout_clean'].astype('category')\n",
    "\n",
    "# Perform inner join on cleaned workout names\n",
    "combined_df = pd.merge(\n",
    "    gym_members_df,\n",
    "    workout_tracker_df,\n",
    "    how='inner',\n",
    "    on='workout_clean',\n",
    "    suffixes=('_gym', '_tracker'),\n",
    "    copy=False     # avoid unnecessary copies for speed\n",
    ")\n",
    "\n",
    "print(f\"Combined df shape: {combined_df.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "05b13f93-5f41-47ed-a6e5-8b1b25906bbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello\n"
     ]
    }
   ],
   "source": [
    "print(\"hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "961cd53c-c0d6-4916-b2d0-c706010dc12d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape: (1630286, 36)\n",
      "Columns: ['Age_gym', 'Gender_gym', 'Weight (kg)_gym', 'Height (m)', 'Max_BPM', 'Avg_BPM', 'Resting_BPM', 'Session_Duration (hours)', 'Calories_Burned', 'Workout_Type', 'Fat_Percentage', 'Water_Intake (liters)', 'Workout_Frequency (days/week)', 'Experience_Level', 'BMI', 'workout_clean', 'User ID', 'Age_tracker', 'Gender_tracker', 'Height (cm)', 'Weight (kg)_tracker', 'Workout Type', 'Workout Duration (mins)', 'Calories Burned', 'Heart Rate (bpm)', 'Steps Taken', 'Distance (km)', 'Workout Intensity', 'Sleep Hours', 'Water Intake (liters)', 'Daily Calories Intake', 'Resting Heart Rate (bpm)', 'VO2 Max', 'Body Fat (%)', 'Mood Before Workout', 'Mood After Workout']\n",
      "Column 'workout_clean': 1630286 values, nulls=0\n",
      "Column 'Experience_Level': 1630286 values, nulls=0\n",
      "Column 'Workout Intensity': 1630286 values, nulls=0\n",
      "Sample unique workout_clean values: ['yoga' 'hiit' 'cardio' 'strength']\n",
      "Numerical cols count: 28; Categorical cols count: 8\n",
      "Categorical features: ['Gender_gym', 'Workout Intensity']\n",
      "Numerical features: ['Age_gym', 'Weight (kg)_gym', 'Height (m)', 'Max_BPM', 'Avg_BPM', 'Resting_BPM', 'Session_Duration (hours)', 'Workout Duration (mins)', 'Calories Burned', 'Heart Rate (bpm)', 'Steps Taken', 'Distance (km)']\n",
      "Using 'Experience_Level' as target\n",
      "Train shape: (1304228, 14), Test shape: (326058, 14)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# --- Your merged DataFrame is combined_df ---\n",
    "\n",
    "# 1. Data Summary and Validation\n",
    "print(f\"Data shape: {combined_df.shape}\")\n",
    "print(f\"Columns: {combined_df.columns.tolist()}\")\n",
    "\n",
    "# Check key columns existence\n",
    "required_cols = ['workout_clean', 'Experience_Level', 'Workout Intensity']\n",
    "for col in required_cols:\n",
    "    if col in combined_df.columns:\n",
    "        print(f\"Column '{col}': {combined_df[col].shape[0]} values, nulls={combined_df[col].isnull().sum()}\")\n",
    "    else:\n",
    "        print(f\"Warning: Column '{col}' NOT FOUND in dataset\")\n",
    "\n",
    "# Preview distinct samples in workout_clean\n",
    "if 'workout_clean' in combined_df.columns:\n",
    "    print(\"Sample unique workout_clean values:\", combined_df['workout_clean'].dropna().unique()[:10])\n",
    "\n",
    "# 2. Handle Missing Values Safely\n",
    "num_cols = combined_df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "cat_cols = combined_df.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "print(f\"Numerical cols count: {len(num_cols)}; Categorical cols count: {len(cat_cols)}\")\n",
    "\n",
    "# Fill numerical missing values\n",
    "for col in num_cols:\n",
    "    median_val = combined_df[col].median()\n",
    "    combined_df[col] = combined_df[col].fillna(median_val)\n",
    "    if combined_df[col].isnull().sum() > 0:\n",
    "        print(f\"Warning: Nulls remain in numerical column '{col}' after fillna\")\n",
    "\n",
    "# Fill categorical missing values\n",
    "for col in cat_cols:\n",
    "    combined_df[col] = combined_df[col].fillna('missing')\n",
    "    if combined_df[col].isnull().sum() > 0:\n",
    "        print(f\"Warning: Nulls remain in categorical column '{col}' after fillna\")\n",
    "\n",
    "# 3. Feature and Target Selection\n",
    "\n",
    "# Assuming combined_df already loaded and processed\n",
    "feature_cols = [\n",
    "    'Age_gym', 'Gender_gym', 'Weight (kg)_gym', 'Height (m)', 'Calories_Burned_gym',\n",
    "    'Max_BPM', 'Avg_BPM', 'Resting_BPM', 'Session_Duration (hours)',\n",
    "    'Workout Duration (mins)', 'Calories Burned', 'Heart Rate (bpm)', 'Steps Taken',\n",
    "    'Distance (km)', 'Workout Intensity'\n",
    "]\n",
    "\n",
    "feature_cols = [f for f in feature_cols if f in combined_df.columns]\n",
    "X = combined_df[feature_cols].copy()\n",
    "\n",
    "\n",
    "# Identify categorical and numerical features in X\n",
    "cat_features = [c for c in feature_cols if X[c].dtype == 'object']\n",
    "num_features = [c for c in feature_cols if c not in cat_features]\n",
    "print(f\"Categorical features: {cat_features}\")\n",
    "print(f\"Numerical features: {num_features}\")\n",
    "\n",
    "# Encode categorical features\n",
    "for col in cat_features:\n",
    "    le = LabelEncoder()\n",
    "    X[col] = le.fit_transform(X[col].astype(str))\n",
    "\n",
    "# Select target column\n",
    "if 'Experience_Level' in combined_df.columns:\n",
    "    y = combined_df['Experience_Level']\n",
    "    print(\"Using 'Experience_Level' as target\")\n",
    "elif 'Workout Intensity' in combined_df.columns:\n",
    "    y = combined_df['Workout Intensity']\n",
    "    print(\"Using 'Workout Intensity' as target\")\n",
    "else:\n",
    "    raise ValueError(\"No target column found! Please check your dataset.\")\n",
    "\n",
    "# 4. Scale numerical features\n",
    "scaler = StandardScaler()\n",
    "X[num_features] = scaler.fit_transform(X[num_features])\n",
    "\n",
    "# 5. Train-Test Split (stratify to maintain target distribution)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "print(f\"Train shape: {X_train.shape}, Test shape: {X_test.shape}\")\n",
    "\n",
    "# 6. Model Training & Evaluation\n",
    "model = RandomForestClassifier(n_estimators=200, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"Model accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Classification report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "77f4bd6d-e654-4e91-b31d-ff7b6e08d426",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mShape of X: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mX\u001b[49m.shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m      2\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mMemory usage by columns (MB):\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      3\u001b[39m \u001b[38;5;28mprint\u001b[39m(X.memory_usage(deep=\u001b[38;5;28;01mTrue\u001b[39;00m) / \u001b[32m1024\u001b[39m**\u001b[32m2\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'X' is not defined"
     ]
    }
   ],
   "source": [
    "print(f\"Shape of X: {X.shape}\")\n",
    "print(\"Memory usage by columns (MB):\")\n",
    "print(X.memory_usage(deep=True) / 1024**2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c2ce046-b6ca-451e-8828-f6c4e3b539fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: Fast categorical encoding using pandas categorical dtype\n",
    "\n",
    "# Copy X to avoid modifying original DataFrame\n",
    "X_encoded = X.copy()\n",
    "\n",
    "# List of categorical columns to encode\n",
    "categorical_cols = ['Gender_gym', 'Workout Intensity']\n",
    "\n",
    "for col in categorical_cols:\n",
    "    if col in X_encoded.columns:\n",
    "        # Convert column to category dtype and get integer codes fast\n",
    "        X_encoded[col] = X_encoded[col].astype('category').cat.codes\n",
    "\n",
    "# Check encoding result summary\n",
    "print(\"Categorical columns encoded:\")\n",
    "for col in categorical_cols:\n",
    "    if col in X_encoded.columns:\n",
    "        print(f\"{col}: {X_encoded[col].nunique()} unique categories encoded\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6f67cd0-7254-46fe-99c3-46b0656c2523",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Identify numerical columns (features minus categorical)\n",
    "numerical_cols = [col for col in X_encoded.columns if col not in categorical_cols]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_encoded[numerical_cols] = scaler.fit_transform(X_encoded[numerical_cols])\n",
    "\n",
    "# Preview scaled features\n",
    "print(\"Preview scaled numerical features:\")\n",
    "print(X_encoded[numerical_cols].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28718db9-596c-4eb8-b979-e370a241de9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# Encode target if needed\n",
    "if y.dtype == 'object' or str(y.dtype) == 'category':\n",
    "    target_le = LabelEncoder()\n",
    "    y_encoded = target_le.fit_transform(y.astype(str))\n",
    "else:\n",
    "    y_encoded = y\n",
    "\n",
    "# Train-test split with stratify to keep target distribution balanced\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_encoded, y_encoded, test_size=0.2, random_state=42, stratify=y_encoded\n",
    ")\n",
    "\n",
    "# Initialize and train model\n",
    "rf_model = RandomForestClassifier(n_estimators=200, random_state=42, n_jobs=-1)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict and evaluate\n",
    "y_pred = rf_model.predict(X_test)\n",
    "\n",
    "print(f\"Accuracy on test set: {accuracy_score(y_test, y_pred):.4f}\")\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
